{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11f5b01c-7731-46fa-bd47-b777a923a4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference profile saved to reference_profile.json\n",
      "spark is initiated\n",
      "preprocess_stages pipeline is called\n",
      "CV is initiated\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/07 21:41:56 WARN CacheManager: Asked to cache already cached data.\n",
      "25/09/07 21:41:56 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run LogisticRegression at: http://localhost:5000/#/experiments/0/runs/db75822c95714b03a6a6049caf57ba1e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/07 21:42:36 WARN BlockManager: Block rdd_98980_0 already exists on this machine; not re-adding it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run RandomForestClassifier at: http://localhost:5000/#/experiments/0/runs/fc2e22cea17a402b950e49cbc7bea626\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n",
      "GBTClassifier\n",
      "üèÉ View run GBTClassifier at: http://localhost:5000/#/experiments/0/runs/08d4db7efcd84bf8bd6fb07fb6f8629b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n",
      "DecisionTreeClassifier\n",
      "üèÉ View run DecisionTreeClassifier at: http://localhost:5000/#/experiments/0/runs/c8fcbefac6ac417ea8b7a871acd07489\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n",
      "NaiveBayes\n",
      "üèÉ View run NaiveBayes at: http://localhost:5000/#/experiments/0/runs/122f8f67d8f24fb594a21a8fde6ce1b1\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n",
      "LinearSVC\n",
      "üèÉ View run LinearSVC at: http://localhost:5000/#/experiments/0/runs/e8d4d706d1954e64a7aadbc27a9def30\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n",
      "\n",
      " Best Pipeline Model: GBTClassificationModel: uid = GBTClassifier_1ed4600329c9, numTrees=10, numClasses=2, numFeatures=8\n",
      "Logs are added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/07 21:46:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'TitanicClassifier' already exists. Creating a new version of this model...\n",
      "2025/09/07 21:46:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: TitanicClassifier, version 14\n",
      "Created version '14' of model 'TitanicClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.models.model.ModelInfo object at 0x7ea72b3e3e00>\n",
      "None\n",
      "üèÉ View run TitanicClassifier at: http://localhost:5000/#/experiments/0/runs/c5beaf0187ea421488b0b80aa5243562\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Importing the required packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Imputer, OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier, NaiveBayes, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.types import *\n",
    "from deployment import deploy_best_model\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from spark_Session import spark_session\n",
    "from preprocessing import preprocess_data\n",
    "from ref_profile import build_reference_profile\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import mlflow.spark # Removed due to compatibility issue\n",
    "\n",
    "import os\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "registered_model_name=\"TitanicClassifier\"\n",
    "\n",
    "\n",
    "# Create artifacts folder and two sub folders for confusion matrix and evaluation report\n",
    "artifact_folder = \"artifacts_temp\"\n",
    "conf_mat_folder = os.path.join(artifact_folder, \"confusion_matrix\")\n",
    "eval_report_folder =  os.path.join(artifact_folder, \"evaluation_report\")\n",
    "if not os.path.exists(conf_mat_folder):\n",
    "  os.makedirs(conf_mat_folder)\n",
    "if not os.path.exists(eval_report_folder):\n",
    "  os.makedirs(eval_report_folder)\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(r\"/home/sridharsg/Documents/AILabProject_Updated/train.csv\")\n",
    "reference_profile = build_reference_profile(df)\n",
    "\n",
    "os.makedirs(\"deployment\", exist_ok=True)\n",
    "with open(\"deployment/reference_profile.json\", \"w\") as f:\n",
    "    json.dump(reference_profile, f, indent=4)\n",
    "\n",
    "print(\"Reference profile saved to reference_profile.json\")\n",
    "\n",
    "# Initiate spark session and mlflow\n",
    "spark = spark_session()\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"PassengerId\", IntegerType(), True),\n",
    "    StructField(\"Survived\", IntegerType(), True),\n",
    "    StructField(\"Pclass\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Sex\", StringType(), True),\n",
    "    StructField(\"Age\", DoubleType(), True),\n",
    "    StructField(\"SibSp\", IntegerType(), True),\n",
    "    StructField(\"Parch\", IntegerType(), True),\n",
    "    StructField(\"Ticket\", StringType(), True),\n",
    "    StructField(\"Fare\", DoubleType(), True),\n",
    "    StructField(\"Cabin\", StringType(), True),\n",
    "    StructField(\"Embarked\", StringType(), True),\n",
    "])\n",
    "df = spark.read.csv(r\"/home/sridharsg/Documents/AILabProject_Updated/train.csv\", header=True, inferSchema=True)\n",
    "df = df.withColumnRenamed('Survived', 'label')\n",
    "print('spark is initiated')\n",
    "# Splitting the dataset\n",
    "train_df = df.randomSplit([0.8, 0.2], seed=42)[0]\n",
    "test_df = df.randomSplit([0.8, 0.2], seed=42)[1]\n",
    "\n",
    "# Function call of Data Preprocessing Pipeline\n",
    "preprocess_stages = preprocess_data()\n",
    "print('preprocess_stages pipeline is called')\n",
    "# Defining the Models\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label')\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='label')\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "nb = NaiveBayes(featuresCol='features', labelCol='label')\n",
    "lsvc = LinearSVC(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "lr_paramGrid = (ParamGridBuilder()\n",
    "              .addGrid(lr.regParam, [0.1, 0.01])\n",
    "              .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "              .build())\n",
    "\n",
    "rf_paramGrid = (ParamGridBuilder()\n",
    "              .addGrid(rf.numTrees, [10, 20])\n",
    "              .addGrid(rf.maxDepth, [5, 10])\n",
    "              .addGrid(rf.impurity, ['gini', 'entropy'])\n",
    "              .build())\n",
    "\n",
    "gbt_paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(gbt.maxIter, [10, 20])\n",
    "                .addGrid(gbt.stepSize, [0.1, 0.01])\n",
    "                .addGrid(gbt.maxDepth, [5, 10])\n",
    "                .build())\n",
    "\n",
    "dt_paramGrid = (ParamGridBuilder()\n",
    "              .addGrid(dt.maxDepth, [5, 10])\n",
    "              .addGrid(dt.impurity, ['gini', 'entropy'])\n",
    "              .build())\n",
    "\n",
    "nb_paramGrid = (ParamGridBuilder()\n",
    "              .addGrid(nb.smoothing, [1.0, 2.0])\n",
    "              .build())\n",
    "\n",
    "lsvc_paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(lsvc.maxIter, [10, 20])\n",
    "                .addGrid(lsvc.regParam, [0.1, 0.01])\n",
    "                .build())\n",
    "\n",
    "pipelines = [(Pipeline(stages=preprocess_stages + [lr]), lr_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [rf]), rf_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [gbt]), gbt_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [dt]), dt_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [nb]), nb_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [lsvc]), lsvc_paramGrid)]\n",
    "\n",
    "#  Performance Metrics\n",
    "accuracy = MulticlassClassificationEvaluator(labelCol='label', metricName='accuracy')\n",
    "f1 = MulticlassClassificationEvaluator(labelCol='label', metricName='f1')\n",
    "auc = BinaryClassificationEvaluator(labelCol='label', metricName='areaUnderROC')\n",
    "precision = MulticlassClassificationEvaluator(labelCol='label', metricName='precisionByLabel')\n",
    "\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "best_auc = 0\n",
    "best_precision = 0\n",
    "best_f1 = 0\n",
    "\n",
    "train_df = train_df.coalesce(4).cache()\n",
    "test_df = test_df.coalesce(2).cache()\n",
    "print('CV is initiated')\n",
    "# Training the models\n",
    "for pipeline, paramGrid in pipelines:\n",
    "  model_name = pipeline.getStages()[-1].__class__.__name__\n",
    "  print(model_name)        \n",
    "  crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=accuracy,\n",
    "                              numFolds=5,\n",
    "                              seed=42,\n",
    "                              parallelism=4)\n",
    "\n",
    "  #time=datetime.now().strftime(\"%d%m%Y%H%M%S\")\n",
    "  with mlflow.start_run(run_name=model_name):\n",
    "      # mlflow.spark.autolog() # Removed due to compatibility issue\n",
    "\n",
    "      cvModel = crossval.fit(train_df)\n",
    "      predictions = cvModel.transform(test_df)\n",
    "\n",
    "      accuracy_score = accuracy.evaluate(predictions)\n",
    "      f1_score = f1.evaluate(predictions)\n",
    "      auc_score = auc.evaluate(predictions)\n",
    "      precision_score = precision.evaluate(predictions)\n",
    "\n",
    "      # Log parameters and metrics manually\n",
    "      best_model_stage = cvModel.bestModel.stages[-1]\n",
    "      best_params = {param.name: best_model_stage.getOrDefault(param)\n",
    "                    for param in best_model_stage.extractParamMap()}\n",
    "      mlflow.log_params(best_params)\n",
    "      '''\n",
    "      # Save params to JSON for artifacts\n",
    "      with open(\"artifacts/best_params.json\", \"w\") as f:\n",
    "          json.dump(best_params, f, indent=2)\n",
    "      \n",
    "      unique_params = {f\"{model_name}.{k}\": v for k, v in best_params.items()}\n",
    "      mlflow.log_params(unique_params)\n",
    "      '''\n",
    "      \n",
    "      mlflow.log_metric('accuracy', accuracy_score)\n",
    "      mlflow.log_metric('f1', f1_score)\n",
    "      mlflow.log_metric('auc', auc_score)\n",
    "      mlflow.log_metric('precision', precision_score)\n",
    "\n",
    "      # Confusion Matrix plot\n",
    "      conf_mat = confusion_matrix(predictions.select('label').toPandas(), predictions.select('prediction').toPandas())\n",
    "\n",
    "      plt.figure(figsize=(10, 5))\n",
    "      sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Survived', 'Not Survived'], yticklabels=['Survived', 'Not Survived'])\n",
    "      plt.xlabel('Predicted')\n",
    "      plt.ylabel('Actual')\n",
    "      plt.title('Confusion Matrix')\n",
    "      cm_file = os.path.join(conf_mat_folder, f\"{model_name}_confusion_matrix.png\")\n",
    "      plt.savefig(cm_file)\n",
    "      plt.close()\n",
    "\n",
    "      # Log confusion matrix\n",
    "      mlflow.log_artifact(cm_file)\n",
    "\n",
    "      report = {\n",
    "          'accuracy': accuracy_score,\n",
    "          'f1': f1_score,\n",
    "          'auc': auc_score,\n",
    "          'precision': precision_score\n",
    "      }\n",
    "      report_file = os.path.join(eval_report_folder, f\"{model_name}_evaluation_report.json\")\n",
    "      with open(report_file, 'w') as f:\n",
    "          json.dump(report, f, indent=2)\n",
    "\n",
    "      #Log evaluation report\n",
    "      mlflow.log_artifact(report_file)\n",
    "    \n",
    "      if accuracy_score > best_acc:\n",
    "        best_acc = accuracy_score\n",
    "        best_f1 = f1_score\n",
    "        best_auc = auc_score\n",
    "        best_precision = precision_score\n",
    "        best_model = cvModel\n",
    "\n",
    "best_pipeline_model = best_model.bestModel\n",
    "print('\\n Best Pipeline Model:', best_pipeline_model.stages[-1])\n",
    "\n",
    "best_pred = best_pipeline_model.transform(test_df)\n",
    "\n",
    "# Inspect stages + log parameters uniquely\n",
    "for stage in best_pipeline_model.stages:\n",
    "      stage_name = stage.__class__.__name__\n",
    "      stage_params = {\n",
    "          f\"{stage_name}.{p.name}\": stage.getOrDefault(p) if stage.isSet(p) else None\n",
    "          for p in stage.params\n",
    "      }\n",
    "      prefixed_params = {f\"{stage_name}.{k}\": v for k, v in stage_params.items()}\n",
    "      #mlflow.log_params(prefixed_params)\n",
    "      #mlflow.log_params(stage_params)\n",
    "\n",
    "    \n",
    "    # ---------------- Log Metrics ----------------\n",
    "with mlflow.start_run(run_name=registered_model_name):\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", best_acc)\n",
    "    mlflow.log_metric(\"f1\", best_f1)\n",
    "    mlflow.log_metric(\"auc\", best_auc)\n",
    "    mlflow.log_metric(\"precision\", best_precision)\n",
    "    print('Logs are added')\n",
    "    # Log model\n",
    "    model_info = mlflow.spark.log_model(\n",
    "            spark_model=best_pipeline_model,\n",
    "            artifact_path=\"spark-model\",\n",
    "            registered_model_name=registered_model_name,\n",
    "            await_registration_for=300\n",
    "        )\n",
    "    print(model_info)\n",
    "    print(model_info.signature)\n",
    "\n",
    "time.sleep(200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e85f44f-2097-4429-9401-8cbbd8588665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ModelVersion: aliases=[], creation_timestamp=1757243314096, current_stage='Archived', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757261194629, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='b776959e07fe4c7b8dfbef13b3505c31', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/b776959e07fe4c7b8dfbef13b3505c31/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='12'>, <ModelVersion: aliases=[], creation_timestamp=1757237802119, current_stage='Staging', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757240421145, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='3ab28c158916468b8ed40c1483b85e70', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/3ab28c158916468b8ed40c1483b85e70/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='10'>, <ModelVersion: aliases=[], creation_timestamp=1757261784185, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757261784185, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='c5beaf0187ea421488b0b80aa5243562', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/c5beaf0187ea421488b0b80aa5243562/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='14'>, <ModelVersion: aliases=[], creation_timestamp=1757260961664, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757261194629, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='b6c8ebf5f1684582aa779dca51c16293', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/b6c8ebf5f1684582aa779dca51c16293/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='13'>]\n",
      "14\n",
      "[<ModelVersion: aliases=[], creation_timestamp=1757243314096, current_stage='Archived', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757261194629, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='b776959e07fe4c7b8dfbef13b3505c31', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/b776959e07fe4c7b8dfbef13b3505c31/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='12'>, <ModelVersion: aliases=[], creation_timestamp=1757237802119, current_stage='Staging', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757240421145, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='3ab28c158916468b8ed40c1483b85e70', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/3ab28c158916468b8ed40c1483b85e70/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='10'>, <ModelVersion: aliases=[], creation_timestamp=1757261784185, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757261784185, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='c5beaf0187ea421488b0b80aa5243562', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/c5beaf0187ea421488b0b80aa5243562/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='14'>, <ModelVersion: aliases=[], creation_timestamp=1757260961664, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757261194629, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='b6c8ebf5f1684582aa779dca51c16293', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/b6c8ebf5f1684582aa779dca51c16293/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='13'>]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "new_version = None\n",
    "timeout = 1000   # seconds\n",
    "poll_interval = 5\n",
    "start = time.time()\n",
    "\n",
    "while time.time() - start < timeout:\n",
    "    latest_versions = client.get_latest_versions(registered_model_name)\n",
    "    print(latest_versions)\n",
    "    if latest_versions:\n",
    "        # Take the most recent version\n",
    "        new_version = max(int(v.version) for v in latest_versions)\n",
    "        print(new_version)\n",
    "        break\n",
    "    time.sleep(poll_interval)\n",
    "\n",
    "print(latest_versions)\n",
    "print(new_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd8d465-ccfa-43fb-8db1-ddcab84842f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model TitanicClassifier version 14 moved to Staging\n",
      "Accuracy Score: 0.8689655172413793\n"
     ]
    }
   ],
   "source": [
    "# Move to Staging\n",
    "client.transition_model_version_stage(\n",
    "    name=registered_model_name,\n",
    "    version=new_version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "print(f\"Model {registered_model_name} version {new_version} moved to Staging\")\n",
    "print(\"Accuracy Score:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8623bc93-09dc-4560-b24a-1086eed8003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/07 21:50:01 INFO mlflow.spark: URI 'models:/TitanicClassifier/Production/sparkml' does not point to the current DFS.\n",
      "2025/09/07 21:50:01 INFO mlflow.spark: File 'models:/TitanicClassifier/Production/sparkml' not found on DFS. Will attempt to upload the file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: version 14 with accuracy 0.8690\n",
      "Model TitanicClassifier version 14 promoted to Production.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaged Production model v14 saved locally at: deployment/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from deployment import deploy_best_model\n",
    "\n",
    "deploy_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6af540-089d-4e50-9e32-701757e1c7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
