{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11f5b01c-7731-46fa-bd47-b777a923a4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference profile saved to reference_profile.json\n",
      "spark is initiated\n",
      "preprocess_stages pipeline is called\n",
      "CV is initiated\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/07 14:56:16 WARN CacheManager: Asked to cache already cached data.\n",
      "25/09/07 14:56:16 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LogisticRegression at: http://localhost:5000/#/experiments/0/runs/8942a009a96b4037968ae94b79e51cf7\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n",
      "RandomForestClassifier\n",
      "🏃 View run RandomForestClassifier at: http://localhost:5000/#/experiments/0/runs/0fed943632b24ea5ab1d6ee0e2a185d2\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n",
      "GBTClassifier\n",
      "🏃 View run GBTClassifier at: http://localhost:5000/#/experiments/0/runs/a4bd0d2c739049809924ceb7aee94db8\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n",
      "DecisionTreeClassifier\n",
      "🏃 View run DecisionTreeClassifier at: http://localhost:5000/#/experiments/0/runs/bd3ce95d9294451bb69e545405034613\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n",
      "NaiveBayes\n",
      "🏃 View run NaiveBayes at: http://localhost:5000/#/experiments/0/runs/c6bed27f46c74f658c877b0637a10d5f\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n",
      "LinearSVC\n",
      "🏃 View run LinearSVC at: http://localhost:5000/#/experiments/0/runs/c5c0bb7b17ce4c2b8879a2fb6b63d9bf\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n",
      "\n",
      " Best Pipeline Model: GBTClassificationModel: uid = GBTClassifier_44269dff7048, numTrees=10, numClasses=2, numFeatures=8\n",
      "Logs are added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/07 14:59:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'TitanicClassifier' already exists. Creating a new version of this model...\n",
      "2025/09/07 14:59:54 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: TitanicClassifier, version 9\n",
      "Created version '9' of model 'TitanicClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.models.model.ModelInfo object at 0x76a59b2e3680>\n",
      "None\n",
      "🏃 View run TitanicClassifier at: http://localhost:5000/#/experiments/0/runs/228bd88cf8d949d0ba8261c40c2dbb3e\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/0\n",
      "[<ModelVersion: aliases=[], creation_timestamp=1757237394064, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237394064, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='228bd88cf8d949d0ba8261c40c2dbb3e', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/228bd88cf8d949d0ba8261c40c2dbb3e/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='9'>, <ModelVersion: aliases=[], creation_timestamp=1757233543099, current_stage='Archived', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757236839429, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='fe70e23ab4754ff6ae3a79b320c5fb82', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/fe70e23ab4754ff6ae3a79b320c5fb82/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='3'>, <ModelVersion: aliases=[], creation_timestamp=1757236638996, current_stage='Staging', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757236839247, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='e6c2d156a66849279d40b0532f292112', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/e6c2d156a66849279d40b0532f292112/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='8'>, <ModelVersion: aliases=[], creation_timestamp=1757236064435, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757236839429, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='12216510d7884bf2b1800d25bad1bdce', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/12216510d7884bf2b1800d25bad1bdce/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='7'>]\n",
      "9\n",
      "[<ModelVersion: aliases=[], creation_timestamp=1757237394064, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237394064, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='228bd88cf8d949d0ba8261c40c2dbb3e', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/228bd88cf8d949d0ba8261c40c2dbb3e/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='9'>, <ModelVersion: aliases=[], creation_timestamp=1757233543099, current_stage='Archived', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757236839429, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='fe70e23ab4754ff6ae3a79b320c5fb82', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/fe70e23ab4754ff6ae3a79b320c5fb82/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='3'>, <ModelVersion: aliases=[], creation_timestamp=1757236638996, current_stage='Staging', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757236839247, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='e6c2d156a66849279d40b0532f292112', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/e6c2d156a66849279d40b0532f292112/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='8'>, <ModelVersion: aliases=[], creation_timestamp=1757236064435, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757236839429, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='12216510d7884bf2b1800d25bad1bdce', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/12216510d7884bf2b1800d25bad1bdce/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='7'>]\n",
      "9\n",
      "Model TitanicClassifier version 9 moved to Staging\n",
      "Accuracy Score: 0.8689655172413793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/07 15:03:14 INFO mlflow.spark: URI 'models:/TitanicClassifier/Production/sparkml' does not point to the current DFS.\n",
      "2025/09/07 15:03:14 INFO mlflow.spark: File 'models:/TitanicClassifier/Production/sparkml' not found on DFS. Will attempt to upload the file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: version 6 with Accuracy 0.8690\n",
      "Model TitanicClassifier version 6 promoted to Production.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'classification_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 290\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistered_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m moved to Staging\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    288\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy Score:\u001b[39m\u001b[33m\"\u001b[39m, best_acc)\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[43mdeploy_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/classification_model/deployment.py:46\u001b[39m, in \u001b[36mdeploy_best_model\u001b[39m\u001b[34m(tracking_uri, registered_model_name, output_dir, metric_name)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Package model\u001b[39;00m\n\u001b[32m     45\u001b[39m model_uri = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodels:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistered_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/Production\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m spark_model = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(output_dir):\n\u001b[32m     49\u001b[39m     shutil.rmtree(output_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/mlflow/spark/__init__.py:961\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model_uri, dfs_tmpdir, dst_path)\u001b[39m\n\u001b[32m    959\u001b[39m sparkml_model_uri = append_to_uri_path(model_uri, flavor_conf[\u001b[33m\"\u001b[39m\u001b[33mmodel_data\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    960\u001b[39m local_sparkml_model_path = os.path.join(local_mlflow_model_path, flavor_conf[\u001b[33m\"\u001b[39m\u001b[33mmodel_data\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparkml_model_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdfs_tmpdir_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdfs_tmpdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_sparkml_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/mlflow/spark/__init__.py:885\u001b[39m, in \u001b[36m_load_model\u001b[39m\u001b[34m(model_uri, dfs_tmpdir_base, local_model_path)\u001b[39m\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_model_databricks_dbfs(\n\u001b[32m    882\u001b[39m         dfs_tmpdir, local_model_path \u001b[38;5;129;01mor\u001b[39;00m _download_artifact_from_uri(model_uri)\n\u001b[32m    883\u001b[39m     )\n\u001b[32m    884\u001b[39m model_uri = _HadoopFileSystem.maybe_copy_from_uri(model_uri, dfs_tmpdir, local_model_path)\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPipelineModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/util.py:717\u001b[39m, in \u001b[36mMLReadable.load\u001b[39m\u001b[34m(cls, path)\u001b[39m\n\u001b[32m    714\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) -> RL:\n\u001b[32m    716\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/pipeline.py:293\u001b[39m, in \u001b[36mPipelineModelReader.load\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaMLReader(cast(Type[\u001b[33m\"\u001b[39m\u001b[33mJavaMLReadable[PipelineModel]\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m.cls)).load(path)\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     uid, stages = \u001b[43mPipelineSharedReadWrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparkSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PipelineModel(stages=cast(List[Transformer], stages))._resetUid(uid)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/pipeline.py:451\u001b[39m, in \u001b[36mPipelineSharedReadWrite.load\u001b[39m\u001b[34m(metadata, sc, path)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, stageUid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stageUids):\n\u001b[32m    448\u001b[39m     stagePath = PipelineSharedReadWrite.getStagePath(\n\u001b[32m    449\u001b[39m         stageUid, index, \u001b[38;5;28mlen\u001b[39m(stageUids), stagesDir\n\u001b[32m    450\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     stage: \u001b[33m\"\u001b[39m\u001b[33mPipelineStage\u001b[39m\u001b[33m\"\u001b[39m = \u001b[43mDefaultParamsReader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadParamsInstance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstagePath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    452\u001b[39m     stages.append(stage)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (metadata[\u001b[33m\"\u001b[39m\u001b[33muid\u001b[39m\u001b[33m\"\u001b[39m], stages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/util.py:1006\u001b[39m, in \u001b[36mDefaultParamsReader.loadParamsInstance\u001b[39m\u001b[34m(path, sc)\u001b[39m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1005\u001b[39m     pythonClassName = metadata[\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[33morg.apache.spark\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpyspark\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m py_type: Type[RL] = \u001b[43mDefaultParamsReader\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__get_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpythonClassName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1007\u001b[39m instance = py_type.load(path)\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m instance\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/util.py:907\u001b[39m, in \u001b[36mDefaultParamsReader.__get_class\u001b[39m\u001b[34m(clazz)\u001b[39m\n\u001b[32m    905\u001b[39m parts = clazz.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    906\u001b[39m module = \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.join(parts[:-\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m m = \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfromlist\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(m, parts[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'classification_model'"
     ]
    }
   ],
   "source": [
    "# Importing the required packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Imputer, OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, DecisionTreeClassifier, NaiveBayes, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.types import *\n",
    "from deployment import deploy_best_model\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from spark_Session import spark_session\n",
    "from preprocessing import preprocess_data\n",
    "from ref_profile import build_reference_profile\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import mlflow.spark # Removed due to compatibility issue\n",
    "\n",
    "import os\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "registered_model_name=\"TitanicClassifier\"\n",
    "\n",
    "\n",
    "# Create artifacts folder and two sub folders for confusion matrix and evaluation report\n",
    "artifact_folder = \"artifacts_temp\"\n",
    "conf_mat_folder = os.path.join(artifact_folder, \"confusion_matrix\")\n",
    "eval_report_folder =  os.path.join(artifact_folder, \"evaluation_report\")\n",
    "if not os.path.exists(conf_mat_folder):\n",
    "  os.makedirs(conf_mat_folder)\n",
    "if not os.path.exists(eval_report_folder):\n",
    "  os.makedirs(eval_report_folder)\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(r\"/home/sridharsg/Documents/AILabProject_Updated/train.csv\")\n",
    "reference_profile = build_reference_profile(df)\n",
    "\n",
    "os.makedirs(\"deployment\", exist_ok=True)\n",
    "with open(\"deployment/reference_profile.json\", \"w\") as f:\n",
    "    json.dump(reference_profile, f, indent=4)\n",
    "\n",
    "print(\"Reference profile saved to reference_profile.json\")\n",
    "\n",
    "# Initiate spark session and mlflow\n",
    "spark = spark_session()\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"PassengerId\", IntegerType(), True),\n",
    "    StructField(\"Survived\", IntegerType(), True),\n",
    "    StructField(\"Pclass\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Sex\", StringType(), True),\n",
    "    StructField(\"Age\", DoubleType(), True),\n",
    "    StructField(\"SibSp\", IntegerType(), True),\n",
    "    StructField(\"Parch\", IntegerType(), True),\n",
    "    StructField(\"Ticket\", StringType(), True),\n",
    "    StructField(\"Fare\", DoubleType(), True),\n",
    "    StructField(\"Cabin\", StringType(), True),\n",
    "    StructField(\"Embarked\", StringType(), True),\n",
    "])\n",
    "df = spark.read.csv(r\"/home/sridharsg/Documents/AILabProject_Updated/train.csv\", header=True, inferSchema=True)\n",
    "df = df.withColumnRenamed('Survived', 'label')\n",
    "print('spark is initiated')\n",
    "# Splitting the dataset\n",
    "train_df = df.randomSplit([0.8, 0.2], seed=42)[0]\n",
    "test_df = df.randomSplit([0.8, 0.2], seed=42)[1]\n",
    "\n",
    "# Function call of Data Preprocessing Pipeline\n",
    "preprocess_stages = preprocess_data()\n",
    "print('preprocess_stages pipeline is called')\n",
    "# Defining the Models\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label')\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='label')\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "nb = NaiveBayes(featuresCol='features', labelCol='label')\n",
    "lsvc = LinearSVC(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "lr_paramGrid = (ParamGridBuilder()\n",
    "              .addGrid(lr.regParam, [0.1, 0.01])\n",
    "              .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "              .build())\n",
    "\n",
    "rf_paramGrid = (ParamGridBuilder()\n",
    "              .addGrid(rf.numTrees, [10, 20])\n",
    "              .addGrid(rf.maxDepth, [5, 10])\n",
    "              .addGrid(rf.impurity, ['gini', 'entropy'])\n",
    "              .build())\n",
    "\n",
    "gbt_paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(gbt.maxIter, [10, 20])\n",
    "                .addGrid(gbt.stepSize, [0.1, 0.01])\n",
    "                .addGrid(gbt.maxDepth, [5, 10])\n",
    "                .build())\n",
    "\n",
    "dt_paramGrid = (ParamGridBuilder()\n",
    "              .addGrid(dt.maxDepth, [5, 10])\n",
    "              .addGrid(dt.impurity, ['gini', 'entropy'])\n",
    "              .build())\n",
    "\n",
    "nb_paramGrid = (ParamGridBuilder()\n",
    "              .addGrid(nb.smoothing, [1.0, 2.0])\n",
    "              .build())\n",
    "\n",
    "lsvc_paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(lsvc.maxIter, [10, 20])\n",
    "                .addGrid(lsvc.regParam, [0.1, 0.01])\n",
    "                .build())\n",
    "\n",
    "pipelines = [(Pipeline(stages=preprocess_stages + [lr]), lr_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [rf]), rf_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [gbt]), gbt_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [dt]), dt_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [nb]), nb_paramGrid),\n",
    "            (Pipeline(stages=preprocess_stages + [lsvc]), lsvc_paramGrid)]\n",
    "\n",
    "#  Performance Metrics\n",
    "accuracy = MulticlassClassificationEvaluator(labelCol='label', metricName='accuracy')\n",
    "f1 = MulticlassClassificationEvaluator(labelCol='label', metricName='f1')\n",
    "auc = BinaryClassificationEvaluator(labelCol='label', metricName='areaUnderROC')\n",
    "precision = MulticlassClassificationEvaluator(labelCol='label', metricName='precisionByLabel')\n",
    "\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "best_auc = 0\n",
    "best_precision = 0\n",
    "best_f1 = 0\n",
    "\n",
    "train_df = train_df.coalesce(4).cache()\n",
    "test_df = test_df.coalesce(2).cache()\n",
    "print('CV is initiated')\n",
    "# Training the models\n",
    "for pipeline, paramGrid in pipelines:\n",
    "  model_name = pipeline.getStages()[-1].__class__.__name__\n",
    "  print(model_name)        \n",
    "  crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=accuracy,\n",
    "                              numFolds=5,\n",
    "                              seed=42,\n",
    "                              parallelism=4)\n",
    "\n",
    "  #time=datetime.now().strftime(\"%d%m%Y%H%M%S\")\n",
    "  with mlflow.start_run(run_name=model_name):\n",
    "      # mlflow.spark.autolog() # Removed due to compatibility issue\n",
    "\n",
    "      cvModel = crossval.fit(train_df)\n",
    "      predictions = cvModel.transform(test_df)\n",
    "\n",
    "      accuracy_score = accuracy.evaluate(predictions)\n",
    "      f1_score = f1.evaluate(predictions)\n",
    "      auc_score = auc.evaluate(predictions)\n",
    "      precision_score = precision.evaluate(predictions)\n",
    "\n",
    "      # Log parameters and metrics manually\n",
    "      best_model_stage = cvModel.bestModel.stages[-1]\n",
    "      best_params = {param.name: best_model_stage.getOrDefault(param)\n",
    "                    for param in best_model_stage.extractParamMap()}\n",
    "      mlflow.log_params(best_params)\n",
    "      '''\n",
    "      # Save params to JSON for artifacts\n",
    "      with open(\"artifacts/best_params.json\", \"w\") as f:\n",
    "          json.dump(best_params, f, indent=2)\n",
    "      \n",
    "      unique_params = {f\"{model_name}.{k}\": v for k, v in best_params.items()}\n",
    "      mlflow.log_params(unique_params)\n",
    "      '''\n",
    "      \n",
    "      mlflow.log_metric('accuracy', accuracy_score)\n",
    "      mlflow.log_metric('f1', f1_score)\n",
    "      mlflow.log_metric('auc', auc_score)\n",
    "      mlflow.log_metric('precision', precision_score)\n",
    "\n",
    "      # Confusion Matrix plot\n",
    "      conf_mat = confusion_matrix(predictions.select('label').toPandas(), predictions.select('prediction').toPandas())\n",
    "\n",
    "      plt.figure(figsize=(10, 5))\n",
    "      sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Survived', 'Not Survived'], yticklabels=['Survived', 'Not Survived'])\n",
    "      plt.xlabel('Predicted')\n",
    "      plt.ylabel('Actual')\n",
    "      plt.title('Confusion Matrix')\n",
    "      cm_file = os.path.join(conf_mat_folder, f\"{model_name}_confusion_matrix.png\")\n",
    "      plt.savefig(cm_file)\n",
    "      plt.close()\n",
    "\n",
    "      # Log confusion matrix\n",
    "      mlflow.log_artifact(cm_file)\n",
    "\n",
    "      report = {\n",
    "          'accuracy': accuracy_score,\n",
    "          'f1': f1_score,\n",
    "          'auc': auc_score,\n",
    "          'precision': precision_score\n",
    "      }\n",
    "      report_file = os.path.join(eval_report_folder, f\"{model_name}_evaluation_report.json\")\n",
    "      with open(report_file, 'w') as f:\n",
    "          json.dump(report, f, indent=2)\n",
    "\n",
    "      #Log evaluation report\n",
    "      mlflow.log_artifact(report_file)\n",
    "    \n",
    "      if accuracy_score > best_acc:\n",
    "        best_acc = accuracy_score\n",
    "        best_f1 = f1_score\n",
    "        best_auc = auc_score\n",
    "        best_precision = precision_score\n",
    "        best_model = cvModel\n",
    "\n",
    "best_pipeline_model = best_model.bestModel\n",
    "print('\\n Best Pipeline Model:', best_pipeline_model.stages[-1])\n",
    "\n",
    "best_pred = best_pipeline_model.transform(test_df)\n",
    "\n",
    "# Inspect stages + log parameters uniquely\n",
    "for stage in best_pipeline_model.stages:\n",
    "      stage_name = stage.__class__.__name__\n",
    "      stage_params = {\n",
    "          f\"{stage_name}.{p.name}\": stage.getOrDefault(p) if stage.isSet(p) else None\n",
    "          for p in stage.params\n",
    "      }\n",
    "      prefixed_params = {f\"{stage_name}.{k}\": v for k, v in stage_params.items()}\n",
    "      #mlflow.log_params(prefixed_params)\n",
    "      #mlflow.log_params(stage_params)\n",
    "\n",
    "    \n",
    "    # ---------------- Log Metrics ----------------\n",
    "with mlflow.start_run(run_name=registered_model_name):\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", best_acc)\n",
    "    mlflow.log_metric(\"f1\", best_f1)\n",
    "    mlflow.log_metric(\"auc\", best_auc)\n",
    "    mlflow.log_metric(\"precision\", best_precision)\n",
    "    print('Logs are added')\n",
    "    # Log model\n",
    "    model_info = mlflow.spark.log_model(\n",
    "            spark_model=best_pipeline_model,\n",
    "            artifact_path=\"spark-model\",\n",
    "            registered_model_name=registered_model_name,\n",
    "            await_registration_for=300\n",
    "        )\n",
    "    print(model_info)\n",
    "    print(model_info.signature)\n",
    "\n",
    "time.sleep(200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bd8d465-ccfa-43fb-8db1-ddcab84842f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ModelVersion: aliases=[], creation_timestamp=1757237802119, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237802119, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='3ab28c158916468b8ed40c1483b85e70', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/3ab28c158916468b8ed40c1483b85e70/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='10'>, <ModelVersion: aliases=[], creation_timestamp=1757236064435, current_stage='Archived', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237594576, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='12216510d7884bf2b1800d25bad1bdce', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/12216510d7884bf2b1800d25bad1bdce/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='7'>, <ModelVersion: aliases=[], creation_timestamp=1757237394064, current_stage='Staging', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237594328, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='228bd88cf8d949d0ba8261c40c2dbb3e', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/228bd88cf8d949d0ba8261c40c2dbb3e/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='9'>, <ModelVersion: aliases=[], creation_timestamp=1757235384253, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237594576, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='e224d7e70817431290460803129cc7a8', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/e224d7e70817431290460803129cc7a8/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='6'>]\n",
      "10\n",
      "[<ModelVersion: aliases=[], creation_timestamp=1757237802119, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237802119, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='3ab28c158916468b8ed40c1483b85e70', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/3ab28c158916468b8ed40c1483b85e70/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='10'>, <ModelVersion: aliases=[], creation_timestamp=1757236064435, current_stage='Archived', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237594576, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='12216510d7884bf2b1800d25bad1bdce', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/12216510d7884bf2b1800d25bad1bdce/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='7'>, <ModelVersion: aliases=[], creation_timestamp=1757237394064, current_stage='Staging', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237594328, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='228bd88cf8d949d0ba8261c40c2dbb3e', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/228bd88cf8d949d0ba8261c40c2dbb3e/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='9'>, <ModelVersion: aliases=[], creation_timestamp=1757235384253, current_stage='Production', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1757237594576, metrics=None, model_id=None, name='TitanicClassifier', params=None, run_id='e224d7e70817431290460803129cc7a8', run_link='', source='/home/sridharsg/Documents/AILabProject_Updated/artifacts/0/e224d7e70817431290460803129cc7a8/artifacts/spark-model', status='READY', status_message=None, tags={}, user_id='', version='6'>]\n",
      "10\n",
      "Model TitanicClassifier version 10 moved to Staging\n",
      "Accuracy Score: 0.8689655172413793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/07 15:40:48 INFO mlflow.spark: URI 'models:/TitanicClassifier/Production/sparkml' does not point to the current DFS.\n",
      "2025/09/07 15:40:48 INFO mlflow.spark: File 'models:/TitanicClassifier/Production/sparkml' not found on DFS. Will attempt to upload the file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: version 5 with Accuracy 0.8690\n",
      "Model TitanicClassifier version 5 promoted to Production.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'classification_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistered_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m moved to Staging\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy Score:\u001b[39m\u001b[33m\"\u001b[39m, best_acc)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mdeploy_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/classification_model/deployment.py:46\u001b[39m, in \u001b[36mdeploy_best_model\u001b[39m\u001b[34m(tracking_uri, registered_model_name, output_dir, metric_name)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Package model\u001b[39;00m\n\u001b[32m     45\u001b[39m model_uri = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodels:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistered_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/Production\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m spark_model = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(output_dir):\n\u001b[32m     49\u001b[39m     shutil.rmtree(output_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/mlflow/spark/__init__.py:961\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model_uri, dfs_tmpdir, dst_path)\u001b[39m\n\u001b[32m    959\u001b[39m sparkml_model_uri = append_to_uri_path(model_uri, flavor_conf[\u001b[33m\"\u001b[39m\u001b[33mmodel_data\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    960\u001b[39m local_sparkml_model_path = os.path.join(local_mlflow_model_path, flavor_conf[\u001b[33m\"\u001b[39m\u001b[33mmodel_data\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparkml_model_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdfs_tmpdir_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdfs_tmpdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_sparkml_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/mlflow/spark/__init__.py:885\u001b[39m, in \u001b[36m_load_model\u001b[39m\u001b[34m(model_uri, dfs_tmpdir_base, local_model_path)\u001b[39m\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_model_databricks_dbfs(\n\u001b[32m    882\u001b[39m         dfs_tmpdir, local_model_path \u001b[38;5;129;01mor\u001b[39;00m _download_artifact_from_uri(model_uri)\n\u001b[32m    883\u001b[39m     )\n\u001b[32m    884\u001b[39m model_uri = _HadoopFileSystem.maybe_copy_from_uri(model_uri, dfs_tmpdir, local_model_path)\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPipelineModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/util.py:717\u001b[39m, in \u001b[36mMLReadable.load\u001b[39m\u001b[34m(cls, path)\u001b[39m\n\u001b[32m    714\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) -> RL:\n\u001b[32m    716\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/pipeline.py:293\u001b[39m, in \u001b[36mPipelineModelReader.load\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaMLReader(cast(Type[\u001b[33m\"\u001b[39m\u001b[33mJavaMLReadable[PipelineModel]\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m.cls)).load(path)\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     uid, stages = \u001b[43mPipelineSharedReadWrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparkSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PipelineModel(stages=cast(List[Transformer], stages))._resetUid(uid)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/pipeline.py:451\u001b[39m, in \u001b[36mPipelineSharedReadWrite.load\u001b[39m\u001b[34m(metadata, sc, path)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, stageUid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stageUids):\n\u001b[32m    448\u001b[39m     stagePath = PipelineSharedReadWrite.getStagePath(\n\u001b[32m    449\u001b[39m         stageUid, index, \u001b[38;5;28mlen\u001b[39m(stageUids), stagesDir\n\u001b[32m    450\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     stage: \u001b[33m\"\u001b[39m\u001b[33mPipelineStage\u001b[39m\u001b[33m\"\u001b[39m = \u001b[43mDefaultParamsReader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadParamsInstance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstagePath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    452\u001b[39m     stages.append(stage)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (metadata[\u001b[33m\"\u001b[39m\u001b[33muid\u001b[39m\u001b[33m\"\u001b[39m], stages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/util.py:1006\u001b[39m, in \u001b[36mDefaultParamsReader.loadParamsInstance\u001b[39m\u001b[34m(path, sc)\u001b[39m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1005\u001b[39m     pythonClassName = metadata[\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[33morg.apache.spark\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpyspark\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m py_type: Type[RL] = \u001b[43mDefaultParamsReader\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__get_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpythonClassName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1007\u001b[39m instance = py_type.load(path)\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m instance\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AILabProject_Updated/venv/lib/python3.12/site-packages/pyspark/ml/util.py:907\u001b[39m, in \u001b[36mDefaultParamsReader.__get_class\u001b[39m\u001b[34m(clazz)\u001b[39m\n\u001b[32m    905\u001b[39m parts = clazz.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    906\u001b[39m module = \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.join(parts[:-\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m m = \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfromlist\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(m, parts[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'classification_model'"
     ]
    }
   ],
   "source": [
    "new_version = None\n",
    "timeout = 1000   # seconds\n",
    "poll_interval = 5\n",
    "start = time.time()\n",
    "\n",
    "while time.time() - start < timeout:\n",
    "    latest_versions = client.get_latest_versions(registered_model_name)\n",
    "    print(latest_versions)\n",
    "    if latest_versions:\n",
    "        # Take the most recent version\n",
    "        new_version = max(int(v.version) for v in latest_versions)\n",
    "        print(new_version)\n",
    "        break\n",
    "    time.sleep(poll_interval)\n",
    "\n",
    "print(latest_versions)\n",
    "print(new_version)\n",
    "\n",
    "\n",
    "# Move to Staging\n",
    "client.transition_model_version_stage(\n",
    "    name=registered_model_name,\n",
    "    version=new_version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "print(f\"Model {registered_model_name} version {new_version} moved to Staging\")\n",
    "print(\"Accuracy Score:\", best_acc)\n",
    "\n",
    "deploy_best_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
